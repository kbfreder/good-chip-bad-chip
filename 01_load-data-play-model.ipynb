{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T22:00:04.497423Z",
     "start_time": "2022-05-15T21:59:57.136793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python-3.10.4 (main, Mar 31 2022, 03:38:35) [Clang 12.0.0 ]\n",
      "tensorflow-2.8.0\n",
      "sklearn-1.1.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import itertools\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg19 import VGG19 \n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.densenet import DenseNet201\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print('python-' + sys.version)\n",
    "print('tensorflow-' + tf.__version__)\n",
    "print('sklearn-' + sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:56:21.684613Z",
     "start_time": "2021-04-26T16:56:21.679281Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: define varialbes in a config file\n",
    "# import config as cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T22:00:06.489284Z",
     "start_time": "2022-05-15T22:00:06.484181Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Users/kendra/Data\"\n",
    "PROJECT_DATA_FOLDER = \"Pepsico RnD Potato Lab Dataset\"\n",
    "PROJECT_DATA_DIR = os.path.join(DATA_DIR, PROJECT_DATA_FOLDER)\n",
    "TRAIN_DIR = os.path.join(PROJECT_DATA_DIR, \"Train\")\n",
    "TEST_DIR = os.path.join(PROJECT_DATA_DIR, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T22:11:28.592345Z",
     "start_time": "2022-05-15T22:11:28.584899Z"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_DIR = \".\"\n",
    "MODEL_SAVE_DIR = os.path.join(PROJECT_DIR, \"models\")\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T22:00:07.281896Z",
     "start_time": "2022-05-15T22:00:07.277907Z"
    }
   },
   "outputs": [],
   "source": [
    "target_img_size = (500,500)\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "input_shape = target_img_size + (3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T22:01:43.341592Z",
     "start_time": "2022-05-15T22:01:43.338323Z"
    }
   },
   "outputs": [],
   "source": [
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=2,\n",
    "    shear_range=2,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    validation_split=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T22:26:24.636127Z",
     "start_time": "2022-05-15T22:26:24.624906Z"
    }
   },
   "outputs": [],
   "source": [
    "# here, data is balanced, so we can use accuracy &/or cross entropy\n",
    "METRICS = [\n",
    "    # these needed to be updated from tensorflow verion 2.4\n",
    "    tf.keras.metrics.binary_accuracy, #keras.metrics.BinaryAccuracy(),\n",
    "    tf.keras.metrics.binary_crossentropy, #keras.metrics.BinaryCrossentropy(),\n",
    "          ]\n",
    "LOSS = tf.keras.losses.binary_crossentropy #keras.losses.BinaryCrossentropy\n",
    "\n",
    "def get_model(Model,\n",
    "              dropout_rate,\n",
    "              learn_rate,\n",
    "              metrics=METRICS\n",
    "             ):\n",
    "    # Taken from https://keras.io/guides/transfer_learning/#transfer-learning-amp-finetuning\n",
    "    \n",
    "    # define our base model\n",
    "    base_model = Model(\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=input_shape,\n",
    "        include_top=False\n",
    "    )\n",
    "\n",
    "    # Freeze it\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # create new model on top\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(dropout_rate)(x)\n",
    "    outputs = keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # could try to tune the Optimizer chosen\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=opt, \n",
    "        loss=LOSS,\n",
    "        metrics=metrics\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T22:26:26.521421Z",
     "start_time": "2022-05-15T22:26:26.512851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search\n",
    "model_dict = {\n",
    "    'vgg19': VGG19, \n",
    "    'vgg16': VGG16, \n",
    "    'inception_resnet': InceptionResNetV2, \n",
    "    'densenet': DenseNet201\n",
    "}\n",
    "\n",
    "models = model_dict.keys()\n",
    "dropout_rates =  [0.1, 0.2] #, 0.5] \n",
    "learn_rates = [0.01, 0.001] #, 0.0001]\n",
    "batch_sizes = [16, 32] \n",
    "# default_bs = 32\n",
    "\n",
    "param_dict = dict(\n",
    "    Model=[model_dict[model] for model in models],\n",
    "    dropout_rate=dropout_rates,\n",
    "    learn_rate=learn_rates, \n",
    "    batch_size=batch_sizes\n",
    ")\n",
    "\n",
    "param_keys = list(param_dict.keys()) \n",
    "param_list = list(itertools.product(*(param_dict[key] for key in param_keys)))\n",
    "param_grid = [{param_keys[i]: x[i] for i in range(len(param_keys))} for x in param_list]\n",
    "\n",
    "len(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T22:15:22.567861Z",
     "start_time": "2022-05-15T22:15:22.560916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': <function keras.applications.vgg19.VGG19(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
       " 'dropout_rate': 0.1,\n",
       " 'learn_rate': 0.01,\n",
       " 'batch_size': 16}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define early stopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T22:12:25.205635Z",
     "start_time": "2022-05-15T22:12:25.201564Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loop over grid params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-15T22:32:55.760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'Model': <function VGG19 at 0x7fd5ed35c9d0>, 'dropout_rate': 0.1, 'learn_rate': 0.01}\n",
      "Found 577 images belonging to 2 classes.\n",
      "Found 192 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "grid_results = []\n",
    "\n",
    "for i, params in enumerate(param_grid):\n",
    "#     if i != 0:\n",
    "#         break\n",
    "    print(f\"{i+1}: {params}\")\n",
    "    \n",
    "    if 'batch_size' in params:\n",
    "        bs = params.pop('batch_size')\n",
    "    else:\n",
    "        bs = default_bs\n",
    "        \n",
    "    model = get_model(**params)\n",
    "    \n",
    "    # must define train & val data generators inside loop to enable tuning of batch size\n",
    "    train_gen = data_augmentation.flow_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        subset=\"training\",\n",
    "        class_mode=\"categorical\",\n",
    "        batch_size=bs,\n",
    "        seed=19,\n",
    "    )\n",
    "\n",
    "    val_gen = data_augmentation.flow_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        subset=\"validation\",\n",
    "        class_mode=\"categorical\",\n",
    "        batch_size=bs,\n",
    "        seed=19,\n",
    "    )\n",
    "\n",
    "    classes = list(train_gen.class_indices.keys())\n",
    "\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=val_gen,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # save results\n",
    "    grid_results.append([history, model])\n",
    "    file_name = f'model_{i:02}'\n",
    "    model.save(os.path.join(MODEL_SAVE_DIR, file_name))\n",
    "    \n",
    "#     print(\"\")\n",
    "#     # Note: Here we print out last epoch's metrics, even though we restore best weights.\n",
    "#     # This is just for quick monitoring of grid search results.\n",
    "#     print(f\"Train score: {history.history['accuracy'][-1]:.4f}\")\n",
    "#     print(f\"Val score  : {history.history['val_accuracy'][-1]:.4f}\")\n",
    "#     print(\"---------------------------\")\n",
    "#     print(\"\")\n",
    "    \n",
    "    print(\"\")\n",
    "    # Here we get the best scores\n",
    "    train_scores = history.history['accuracy']\n",
    "    val_scores = history.history['val_accuracy']\n",
    "    print(f\"Train acc: {max(train_scores):.4f}\")\n",
    "    print(f\"Val acc  : {max(val_scores):.4f}\")\n",
    "    print(\"---------------------------\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T02:13:05.709526Z",
     "start_time": "2021-04-17T02:13:05.704789Z"
    }
   },
   "outputs": [],
   "source": [
    "val_scores = [np.max(x[0].history['val_accuracy']) for x in grid_results]\n",
    "\n",
    "base_colors = ['orange', 'blue', 'green', 'pink']\n",
    "colors = [[x]*9 for x in base_colors]\n",
    "colors = [y for x in colors for y in x]\n",
    "\n",
    "model_names = [x.__name__ for x in models]\n",
    "handler = [Patch(facecolor=base_colors[i], label=model_names[i]) for i in range(len(model_names))]\n",
    "\n",
    "w = 0.6\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.bar(xs, val_scores, width=w, color=colors)\n",
    "plt.ylabel(\"Val score (accuracy)\")\n",
    "plt.xlabel(\"Parameter set\")\n",
    "plt.legend(handles=handler, loc=(0.55, 0.75));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspect best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T02:16:41.937428Z",
     "start_time": "2021-04-17T02:16:41.932771Z"
    }
   },
   "outputs": [],
   "source": [
    "val_score_best = np.max(val_scores)\n",
    "print(val_score_best)\n",
    "best_args = [i for i, x in enumerate(val_score_best) if x == val_score_best]\n",
    "len(best_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:55:45.098482Z",
     "start_time": "2021-04-26T16:55:45.092734Z"
    }
   },
   "outputs": [],
   "source": [
    "best_historys = [grid_results[idx][0] for idx in best_args]\n",
    "best_models = [grid_results[idx][1] for idx in best_args]\n",
    "best_params = [param_grid[idx] for idx in best_args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:55:47.767915Z",
     "start_time": "2021-04-26T16:55:47.567193Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, best_history in enumerate(best_historys):\n",
    "    plt.figure()\n",
    "    plt.plot(best_history.history['accuracy'])\n",
    "    plt.plot(best_history.history['val_accuracy'])\n",
    "    plt.ylabel('F1-score')\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend(['Train', 'Val']);\n",
    "    params = best_params[i]\n",
    "    plt.title(f\"{params['Model'].__name__}, dropout: {params['dropout_rate']}, learn rate: {params['learn_rate']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save label dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:56:05.595937Z",
     "start_time": "2021-04-26T16:56:05.591417Z"
    }
   },
   "outputs": [],
   "source": [
    "class_dict = train_gen.class_indices\n",
    "rev_class_dict = {val:key for key,val in class_dict.items()}\n",
    "rev_class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_DICT_PATH = os.path.join(MODEL_SAVE_DIR, 'class-labels.pkl')\n",
    "\n",
    "with open(LABEL_DICT_PATH, 'wb') as file:\n",
    "    pickle.dump(rev_class_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moar tune?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could refine tuning to hone in on other parameters near best model(s)'s parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vs. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:56:54.396364Z",
     "start_time": "2021-04-26T16:56:54.125608Z"
    }
   },
   "outputs": [],
   "source": [
    "test_batch_size = 12\n",
    "\n",
    "# load test data, get labels\n",
    "test_data = image_dataset_from_directory(\n",
    "    directory = TEST_DIR,\n",
    "    image_size=target_img_size,\n",
    "    color_mode='rgb',\n",
    "    batch_size=test_batch_size,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "class_names = test_data.class_names\n",
    "num_test = len(test_data.file_paths)\n",
    "\n",
    "y_test = []\n",
    "for data, labels in test_data.take(ceil(num_test/test_batch_size)):\n",
    "    batch_labels = [class_names[np.argmax(x)] for x in labels]\n",
    "    y_test.extend(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:57:01.034720Z",
     "start_time": "2021-04-26T16:56:56.423085Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate model against test data\n",
    "i = 0\n",
    "m = best_models[i]\n",
    "params = best_params[i]\n",
    "print(f\"{params['Model'].__name__}, dropout: {params['dropout_rate']}, learn rate: {params['learn_rate']}\")\n",
    "test_eval = m.evaluate(test_data, return_dict=True)\n",
    "test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:57:13.304220Z",
     "start_time": "2021-04-26T16:57:08.504765Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_preds = m.predict(test_data)\n",
    "pred_idxs = np.argmax(raw_preds, axis=1)\n",
    "y_pred = [rev_class_dict[x] for x in pred_idxs]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "conf_mtx = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_mtx, annot=True, cmap='gray_r', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\");\n",
    "plt.title(\"Hold-out data predictions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: refine this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:57:48.653380Z",
     "start_time": "2021-04-26T16:57:44.191250Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "m = best_models[i]\n",
    "final_params = best_params[i]\n",
    "print(f\"\"\"{final_params['Model'].__name__}, \n",
    "      dropout: {final_params['dropout_rate']}, \n",
    "      learn rate: {final_params['learn_rate']}\"\"\")\n",
    "test_eval = m.evaluate(test_data, return_dict=True)\n",
    "test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:58:02.086368Z",
     "start_time": "2021-04-26T16:58:02.081970Z"
    }
   },
   "outputs": [],
   "source": [
    "final_params #= {\n",
    "#     'Model': VGG19,\n",
    "#     'dropout_rate': 0.1,\n",
    "#     'learn_rate': 0.0001\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:20:48.703690Z",
     "start_time": "2021-04-26T16:20:48.700703Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_text_file(obj, file_path):\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(str(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:21:24.007584Z",
     "start_time": "2021-04-26T16:21:24.004575Z"
    }
   },
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:21:27.275156Z",
     "start_time": "2021-04-26T16:21:27.246335Z"
    }
   },
   "outputs": [],
   "source": [
    "reload(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:21:29.635989Z",
     "start_time": "2021-04-26T16:21:29.631183Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg.MODEL_PARAM_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:21:36.405424Z",
     "start_time": "2021-04-26T16:21:36.402321Z"
    }
   },
   "outputs": [],
   "source": [
    "save_text_file(final_params, cfg.MODEL_PARAM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:24:49.441990Z",
     "start_time": "2021-04-26T16:24:49.439815Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:24:56.979875Z",
     "start_time": "2021-04-26T16:24:56.976697Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_text_file(file_path, obj_type='list'):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        obj = file.read()\n",
    "    \n",
    "    if obj_type == 'dict':\n",
    "        return ast.literal_eval(obj)\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:24:57.589498Z",
     "start_time": "2021-04-26T16:24:57.585468Z"
    }
   },
   "outputs": [],
   "source": [
    "check = read_text_file(cfg.MODEL_PARAM_PATH, obj_type='dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:26:55.829661Z",
     "start_time": "2021-04-26T16:26:55.827030Z"
    }
   },
   "outputs": [],
   "source": [
    "final_params = {\n",
    "#     'Model': VGG19,\n",
    "    'dropout_rate': 0.1,\n",
    "    'learn_rate': 0.0001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:26:56.395681Z",
     "start_time": "2021-04-26T16:26:56.392942Z"
    }
   },
   "outputs": [],
   "source": [
    "save_text_file(final_params, cfg.MODEL_PARAM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:26:56.865531Z",
     "start_time": "2021-04-26T16:26:56.862422Z"
    }
   },
   "outputs": [],
   "source": [
    "check = read_text_file(cfg.MODEL_PARAM_PATH, obj_type='dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T16:26:59.611277Z",
     "start_time": "2021-04-26T16:26:59.607613Z"
    }
   },
   "outputs": [],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T02:28:53.193947Z",
     "start_time": "2021-04-17T02:28:53.156399Z"
    }
   },
   "outputs": [],
   "source": [
    "# save model params\n",
    "# u.save_pickle_file(final_params, cfg.MODEL_PARAM_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
